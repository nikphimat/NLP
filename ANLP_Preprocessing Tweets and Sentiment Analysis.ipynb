{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANLP HW1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAuyM+eNb6az2+7Y7lAa+Z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhcdyRazAUfD",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQqOA4KassaM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "4aea2889-5857-4801-8949-e0b9d37c9c11"
      },
      "source": [
        "pip install emoji --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
            "\r\u001b[K     |██████▍                         | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20kB 1.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30kB 1.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 40kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=b0aaac0b5e89aae97b6dc3a5ace773fd18f853cb799a835be56e001c8d912112\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB92YXtFFTsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Analysis\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import io\n",
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "#Data Preprocessing and Feature Engineering\n",
        "import unicodedata\n",
        "from textblob import TextBlob\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import emoji\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from pprint import pprint\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "\n",
        "#Model Selection and Validation\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
        "from sklearn.metrics import f1_score, make_scorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRmgGJ8epNgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ba24e50d-3cf2-4aae-fa6e-c04eb9820327"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUk7W6z_NIdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tweets = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/NLP/NLP HW1/train.csv',encoding = \"ISO-8859-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucjj68WNItf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tweets = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/NLP/NLP HW1/test.csv',encoding = \"ISO-8859-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBs6Kn-LLSCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "d33c2ee5-fee8-42cf-a8be-6652360a262b"
      },
      "source": [
        "test_tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7322</td>\n",
              "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7323</td>\n",
              "      <td>@AmericanAir after all, the plane didnÂÃÂªt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7324</td>\n",
              "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7325</td>\n",
              "      <td>@USAirways I can legitimately say that I would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7326</td>\n",
              "      <td>@AmericanAir still no response from AA. great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7315</th>\n",
              "      <td>14637</td>\n",
              "      <td>@JetBlue Traveling with two kids tomorrow (age...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7316</th>\n",
              "      <td>14638</td>\n",
              "      <td>@JetBlue Tx for the info. Just don't understan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7317</th>\n",
              "      <td>14639</td>\n",
              "      <td>@AmericanAir I understand. But why is this the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7318</th>\n",
              "      <td>14640</td>\n",
              "      <td>@USAirways really!??</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7319</th>\n",
              "      <td>14641</td>\n",
              "      <td>@united no I did not make connection.  Your st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7320 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                               text\n",
              "0      7322  @AmericanAir In car gng to DFW. Pulled over 1h...\n",
              "1      7323  @AmericanAir after all, the plane didnÂÃÂªt ...\n",
              "2      7324  @SouthwestAir can't believe how many paying cu...\n",
              "3      7325  @USAirways I can legitimately say that I would...\n",
              "4      7326  @AmericanAir still no response from AA. great ...\n",
              "...     ...                                                ...\n",
              "7315  14637  @JetBlue Traveling with two kids tomorrow (age...\n",
              "7316  14638  @JetBlue Tx for the info. Just don't understan...\n",
              "7317  14639  @AmericanAir I understand. But why is this the...\n",
              "7318  14640                               @USAirways really!??\n",
              "7319  14641  @united no I did not make connection.  Your st...\n",
              "\n",
              "[7320 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmB8UhImQ4rF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "b97ed373-47f9-4e50-d213-205810ae6a4f"
      },
      "source": [
        "sns.countplot(x=train_tweets['Target'], data=train_tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc31aa0deb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aJHDoHEWqTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train_tweets.drop(['Id', 'Target'], axis=1)\n",
        "y = pd.DataFrame(train_tweets['Target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0rZrySrXjKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "35df403a-07c5-48c7-88fb-611ab98b29d5"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@USAirways  ! THE WORST in customer service. @...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@united call wait times are over 20 minutes an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@JetBlue what's up with the random delay on fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@AmericanAir Good morning!  Wondering why my p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@united UA 746. Pacific Rim and Date Night cut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7315</th>\n",
              "      <td>@AmericanAir followback</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7316</th>\n",
              "      <td>@united thanks for the help. Wish the phone re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7317</th>\n",
              "      <td>@usairways the. Worst. Ever. #dca #customerser...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7318</th>\n",
              "      <td>@nrhodes85: look! Another apology. DO NOT FLY ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7319</th>\n",
              "      <td>@united you are by far the worst airline. 4 pl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7320 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text\n",
              "0     @USAirways  ! THE WORST in customer service. @...\n",
              "1     @united call wait times are over 20 minutes an...\n",
              "2     @JetBlue what's up with the random delay on fl...\n",
              "3     @AmericanAir Good morning!  Wondering why my p...\n",
              "4     @united UA 746. Pacific Rim and Date Night cut...\n",
              "...                                                 ...\n",
              "7315                            @AmericanAir followback\n",
              "7316  @united thanks for the help. Wish the phone re...\n",
              "7317  @usairways the. Worst. Ever. #dca #customerser...\n",
              "7318  @nrhodes85: look! Another apology. DO NOT FLY ...\n",
              "7319  @united you are by far the worst airline. 4 pl...\n",
              "\n",
              "[7320 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPaZ2bNlWLYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8e5f552-ce08-4c1d-d9fa-3e8c636a17a3"
      },
      "source": [
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    stripped_text = soup.get_text()\n",
        "    return stripped_text\n",
        "\n",
        "strip_html_tags('<html><h2>Some important text</h2></html>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Some important text'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KRGwAob3UJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "    return input_txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS4iuv8_WMQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eea71c19-1e53-474c-bf00-cfe33ddef135"
      },
      "source": [
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "remove_accented_chars('Sómě Áccěntěd těxt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Some Accented text'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxyzBjpF26S8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X['clean_tweet'] = X['text'].apply(lambda x: remove_pattern(x,\"@[\\w]*\"))\n",
        "#X.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8O8hvKu8nUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def count_regex(pattern, tweet):\n",
        "        #finding all the substring containing the pattern in the tweet\n",
        "        return len(re.findall(pattern, tweet))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys0WyhBLAuIj",
        "colab_type": "text"
      },
      "source": [
        "# **Creating Text Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogbs8mbD8AqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on https://www.freecodecamp.org/news/sentiment-analysis-with-text-mining/\n",
        "\n",
        "def feature_counts(X):\n",
        "        #all the alphanumeric character\n",
        "        count_words = X.apply(lambda x: count_regex(r'\\w+', x)) \n",
        "        count_mentions = X.apply(lambda x: count_regex(r'@\\w+', x))\n",
        "        count_hashtags = X.apply(lambda x: count_regex(r'#\\w+', x))\n",
        "        count_capital_words = X.apply(lambda x: count_regex(r'\\b[A-Z]{2,}\\b', x))\n",
        "        count_excl_quest_marks = X.apply(lambda x: count_regex(r'!|\\?+', x))\n",
        "        count_urls = X.apply(lambda x: count_regex(r'https?://[^\\s]+[\\s]?', x))\n",
        "        # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n",
        "        # Moreover, it will result in having more words in the tweet\n",
        "        count_emojis = X.apply(lambda x: emoji.demojize(x)).apply(lambda x: count_regex(r':[a-z_&]+:', x))\n",
        "        \n",
        "        df = pd.DataFrame({'count_words': count_words\n",
        "                           , 'count_mentions': count_mentions\n",
        "                           , 'count_hashtags': count_hashtags\n",
        "                           , 'count_capital_words': count_capital_words\n",
        "                           , 'count_excl_quest_marks': count_excl_quest_marks\n",
        "                           , 'count_urls': count_urls\n",
        "                           , 'count_emojis': count_emojis\n",
        "                          })\n",
        "        \n",
        "        return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93upCgba8I6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "a16444d1-c58f-4f5d-f1e3-99a4606d76f4"
      },
      "source": [
        "X_feat_counts = feature_counts(X.text)\n",
        "X_feat_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count_words</th>\n",
              "      <th>count_mentions</th>\n",
              "      <th>count_hashtags</th>\n",
              "      <th>count_capital_words</th>\n",
              "      <th>count_excl_quest_marks</th>\n",
              "      <th>count_urls</th>\n",
              "      <th>count_emojis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7315</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7316</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7317</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7318</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7319</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7320 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      count_words  count_mentions  ...  count_urls  count_emojis\n",
              "0              18               2  ...           0             0\n",
              "1              14               1  ...           0             0\n",
              "2              19               1  ...           0             0\n",
              "3              17               1  ...           0             0\n",
              "4              18               1  ...           0             0\n",
              "...           ...             ...  ...         ...           ...\n",
              "7315            2               1  ...           0             0\n",
              "7316           13               1  ...           0             0\n",
              "7317            6               1  ...           0             0\n",
              "7318            8               2  ...           0             0\n",
              "7319           20               1  ...           0             0\n",
              "\n",
              "[7320 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6sIUIXJx8OL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "be302857-b9a2-4c23-eaa3-66eaa258f510"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pZX29h7mrh7",
        "colab_type": "text"
      },
      "source": [
        "# **Custom Extensible Tokenizer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bbnsCeZngMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shorter version of http://sentiment.christopherpotts.net/code-data/happyfuntokenizing.py\n",
        "# Shorter version adapted from https://github.com/dbamman/anlp19/blob/master/1.words/ExploreTokenization.ipynb\n",
        "\n",
        "# The order here is important (match from first to last)\n",
        "import re\n",
        "\n",
        "# Keep usernames together (any token starting with @, followed by A-Z, a-z, 0-9)\n",
        "regexes=(r\"(?:@[\\w_]+)\",\n",
        "\n",
        "# Keep hashtags together (any token starting with #, followed by A-Z, a-z, 0-9, _, or -)\n",
        "r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\",\n",
        "\n",
        "# Keep words with apostrophes, hyphens and underscores together\n",
        "#r\"(?:[a-z][a-z’'\\-_]+[a-z])\",\n",
        "\n",
        "# Keep all other sequences of A-Z, a-z, 0-9, _ together\n",
        "r\"(?:[\\w_]+)\",\n",
        "\n",
        "# Everything else that's not whitespace\n",
        "r\"(?:\\S)\"\n",
        ")\n",
        "\n",
        "big_regex=\"|\".join(regexes)\n",
        "\n",
        "my_extensible_tokenizer = re.compile(big_regex, re.VERBOSE | re.I | re.UNICODE)\n",
        "\n",
        "def my_extensible_tokenize(text):\n",
        "    return my_extensible_tokenizer.findall(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3SA3J-XnhYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = []\n",
        "tokens = [' '.join(my_extensible_tokenize(X.loc[i, \"text\"])) for i in range(len(X))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkrAfc_Rnh1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X[\"token_text\"]=tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5JFuxb8m5ad",
        "colab_type": "text"
      },
      "source": [
        "# **Text Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j53O5Y_uNHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65\n",
        "# Based on https://www.freecodecamp.org/news/sentiment-analysis-with-text-mining/\n",
        "class CleanText(BaseEstimator, TransformerMixin):\n",
        "    def remove_mentions(self, input_text):\n",
        "        return re.sub(r'@\\w+', '', input_text)\n",
        "    \n",
        "    def remove_urls(self, input_text):\n",
        "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
        "    \n",
        "    def emoji_oneword(self, input_text):\n",
        "        # By compressing the underscore, the emoji is kept as one word\n",
        "        return input_text.replace('_','')\n",
        "    \n",
        "    def remove_punctuation(self, input_text):\n",
        "        # Make translation table\n",
        "        punct = string.punctuation\n",
        "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
        "        return input_text.translate(trantab)\n",
        "\n",
        "    def remove_digits(self, input_text):\n",
        "        return re.sub('\\d+', '', input_text)\n",
        "    \n",
        "    def to_lower(self, input_text):\n",
        "        return input_text.lower()\n",
        "    \n",
        "    def stemming(self, input_text):\n",
        "        porter = PorterStemmer()\n",
        "        words = input_text.split() \n",
        "        stemmed_words = [porter.stem(word) for word in words]\n",
        "        return \" \".join(stemmed_words)\n",
        "\n",
        "    def remove_stopwords(self, input_text):\n",
        "        stopwords_list = stopwords.words('english')\n",
        "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
        "        whitelist = [\"n't\", \"not\", \"no\",'who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
        "        words = input_text.split() \n",
        "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
        "        return \" \".join(clean_words) \n",
        "    \n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, **transform_params):\n",
        "        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.stemming).apply(self.remove_stopwords)\n",
        "        return clean_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbr4RzCHu8Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ct = CleanText()\n",
        "clean_text = []\n",
        "clean_text = ct.fit_transform(X.token_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF63G6V7vL9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "750174c1-8ac2-428b-bd26-327ecdc815f4"
      },
      "source": [
        "#empty_clean = clean_text == ''\n",
        "#print('{} records have no words left after text cleaning'.format(clean_text[empty_clean].count()))\n",
        "#clean_text.loc[empty_clean] = '[no_text]'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 records have no words left after text cleaning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTGEtejS0KZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_text = pd.DataFrame(clean_text)\n",
        "clean_text.columns = ['clean_text']\n",
        "X[\"clean_text\"] = clean_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpPFLhQl5lif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2 = pd.concat([X, X_feat_counts], axis=1, sort=False,ignore_index=True)\n",
        "X2.columns = ['text','token_text','clean_text','count_words', 'count_mentions', 'count_hashtags',\n",
        "       'count_capital_words', 'count_excl_quest_marks', 'count_urls',\n",
        "       'count_emojis']\n",
        "X=X2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKXZYD8tAHy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_counts = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
        "                      ,'count_mentions','count_urls','count_words']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9t8rgOYnMrf",
        "colab_type": "text"
      },
      "source": [
        "# **Train-Test-Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wncYIRLWEOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 46)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLx8rK9PI6Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1 = make_scorer(f1_score , average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWQFE_kEnV9M",
        "colab_type": "text"
      },
      "source": [
        "# **GridSearch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2lJ2qbRLxcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeatureExtractor(TransformerMixin, BaseEstimator):\n",
        "    def __init__(self, cols):\n",
        "        self.cols = cols\n",
        "\n",
        "    def transform(self, X, **transform_params):\n",
        "        return X[self.cols]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99-5uzVs0lpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\n",
        "def grid_search_fn(clf, parameters_clf, X_train, X_test, parameters_vect=None, vect=None):\n",
        "    \n",
        "    features = FeatureUnion([('feat_counts', FeatureExtractor(cols=feat_counts))\n",
        "                                 , ('pipe', Pipeline([('cleantext', FeatureExtractor(cols='clean_text')), ('vect', vect)]))]\n",
        "                                , n_jobs=-1\n",
        "                            )\n",
        "    \n",
        "    pipeline = Pipeline([\n",
        "        ('features', features)\n",
        "        , ('classifier', clf)\n",
        "    ])\n",
        "    \n",
        "    # Join the parameters dictionaries together\n",
        "    parameters = dict()\n",
        "    if parameters_vect:\n",
        "        parameters.update(parameters_vect)\n",
        "    parameters.update(parameters_clf)\n",
        "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5,scoring='f1_macro')\n",
        "    \n",
        "    print(\"Performing grid search...\")\n",
        "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
        "    print(\"parameters:\")\n",
        "    pprint(parameters)\n",
        "    t0 = time()\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"done in %0.3fs\" % (time() - t0))\n",
        "    print()\n",
        "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
        "    print(\"Best parameters set:\")\n",
        "    best_parameters = grid_search.best_estimator_.get_params()\n",
        "    for param_name in sorted(parameters.keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "        \n",
        "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
        "    print(\"\\n\")\n",
        "    print(\"Classification Report Test Data\")\n",
        "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
        "                        \n",
        "    return grid_search"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8EN223Ep23a",
        "colab_type": "text"
      },
      "source": [
        "## **Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "162FOgWhCjG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
        "parameters_cvec = {\n",
        "    'features__pipe__vect__max_df': (0.95, 1.0),\n",
        "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2)),\n",
        "    'features__pipe__vect__min_df': (1,2)\n",
        "}\n",
        "parameters_tfidf = {\n",
        "    'features__pipe__vect__max_df': (0.95, 1.0),\n",
        "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2)),\n",
        "    'features__pipe__vect__min_df': (1,2)\n",
        "}\n",
        "\n",
        "# Parameter grid settings for MultinomialNB\n",
        "parameters_MNB = {\n",
        "    'classifier__alpha': (0.25, 0.5, 0.75)\n",
        "}\n",
        "\n",
        "# Parameter grid settings for LogisticRegression\n",
        "parameters_logit = {\n",
        "    'classifier__C': (0.25, 0.5, 1.0),\n",
        "    'classifier__penalty': ('l1', 'l2')\n",
        "}\n",
        "\n",
        "parameters_XGB = {\n",
        "        'classifier__max_depth': [3, 4, 5]\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg6umLQt3xiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MNB = MultinomialNB()\n",
        "logit = LogisticRegression(max_iter=1000)\n",
        "XGB = XGBClassifier(silent=False)\n",
        "cvec = CountVectorizer()\n",
        "tfidf = TfidfVectorizer()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI-VnKdQpsDA",
        "colab_type": "text"
      },
      "source": [
        "# **Logistic Regression with Count Vectorizer**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoONftWvqvb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "ebc7f171-26b2-4b46-9241-0ff467b398b1"
      },
      "source": [
        "# LogisticRegressionWithCvec\n",
        "best_logit_cvec = grid_search_fn(logit, parameters_logit, X_train, X_test, parameters_vect=parameters_cvec, vect=cvec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['features', 'classifier']\n",
            "parameters:\n",
            "{'classifier__C': (0.25, 0.5, 1.0),\n",
            " 'classifier__penalty': ('l1', 'l2'),\n",
            " 'features__pipe__vect__max_df': (0.95, 1.0),\n",
            " 'features__pipe__vect__min_df': (1, 2),\n",
            " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   27.0s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  7.6min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done in 458.051s\n",
            "\n",
            "Best CV score: 0.720\n",
            "Best parameters set:\n",
            "\tclassifier__C: 0.5\n",
            "\tclassifier__penalty: 'l2'\n",
            "\tfeatures__pipe__vect__max_df: 0.95\n",
            "\tfeatures__pipe__vect__min_df: 1\n",
            "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
            "Test score with best_estimator_: 0.777\n",
            "\n",
            "\n",
            "Classification Report Test Data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.84      0.88      0.86       893\n",
            "           0       0.63      0.58      0.60       326\n",
            "           1       0.72      0.66      0.69       245\n",
            "\n",
            "    accuracy                           0.78      1464\n",
            "   macro avg       0.73      0.71      0.72      1464\n",
            "weighted avg       0.77      0.78      0.77      1464\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6fv_x2QPhtf",
        "colab_type": "text"
      },
      "source": [
        "**Best parameters set:**\n",
        "\t\n",
        "  classifier__C: 0.5\n",
        "\t\n",
        "  classifier__penalty: 'l2'\n",
        "\t\n",
        "  features__pipe__vect__max_df: 0.95\n",
        "\t\n",
        "  features__pipe__vect__min_df: 1\n",
        "\t\n",
        "  features__pipe__vect__ngram_range: (1, 1)\n",
        "\n",
        "Test score with best_estimator_: 0.777"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tidFQ-zbxxVc",
        "colab_type": "text"
      },
      "source": [
        "## **Predict F1 score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZjlHSwehxfda",
        "colab": {}
      },
      "source": [
        "y_pred = best_logit_cvec.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OAbmwaqOxfdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f299e36-8f55-4446-e0fc-0bbabd3422b1"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1464,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p829AEH9xfdk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5330de52-863c-4541-983b-404f5465785b"
      },
      "source": [
        "mean_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "mean_f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7167004745108786"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAaa6RmBx7eo",
        "colab_type": "text"
      },
      "source": [
        "# **Logistic Regression with Tfidf Transformer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbdbLa-nmDoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "0ec1254e-31a6-4a7e-8a43-d8ed3af2e1dd"
      },
      "source": [
        "# LogisticRegressionWithTfidf\n",
        "best_logit_tfidf = grid_search_fn(logit, parameters_logit, X_train, X_test, parameters_vect=parameters_tfidf, vect=tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['features', 'classifier']\n",
            "parameters:\n",
            "{'classifier__C': (0.25, 0.5, 1.0),\n",
            " 'classifier__penalty': ('l1', 'l2'),\n",
            " 'features__pipe__vect__max_df': (0.95, 1.0),\n",
            " 'features__pipe__vect__min_df': (1, 2),\n",
            " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   24.9s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  8.5min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done in 515.599s\n",
            "\n",
            "Best CV score: 0.700\n",
            "Best parameters set:\n",
            "\tclassifier__C: 1.0\n",
            "\tclassifier__penalty: 'l2'\n",
            "\tfeatures__pipe__vect__max_df: 0.95\n",
            "\tfeatures__pipe__vect__min_df: 2\n",
            "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
            "Test score with best_estimator_: 0.775\n",
            "\n",
            "\n",
            "Classification Report Test Data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.81      0.92      0.86       893\n",
            "           0       0.65      0.53      0.58       326\n",
            "           1       0.76      0.57      0.65       245\n",
            "\n",
            "    accuracy                           0.78      1464\n",
            "   macro avg       0.74      0.67      0.70      1464\n",
            "weighted avg       0.77      0.78      0.77      1464\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5voL28vaytUR"
      },
      "source": [
        "## **Predict F1 score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_x95cRjTZde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = best_logit_tfidf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vboRZ-zS9h_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4d9928a-33bb-4b6f-f283-eb542f0cc9d1"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1464,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4dDpJXQ2pYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22879e0c-04b2-49c3-debd-52c5957d534f"
      },
      "source": [
        "mean_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "mean_f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6987141291391089"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y3ZapqUBz9GX"
      },
      "source": [
        "# **Multinomial NB with Count Vectorizer**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mpdCjefyz9Gb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "acf08fb4-9728-4980-9238-3c732d26edcd"
      },
      "source": [
        "best_MNB_cvec = grid_search_fn(MNB, parameters_MNB, X_train, X_test, parameters_vect=parameters_cvec, vect=cvec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['features', 'classifier']\n",
            "parameters:\n",
            "{'classifier__alpha': (0.25, 0.5, 0.75),\n",
            " 'features__pipe__vect__max_df': (0.95, 1.0),\n",
            " 'features__pipe__vect__min_df': (1, 2),\n",
            " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    9.1s\n",
            "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   22.3s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done in 22.464s\n",
            "\n",
            "Best CV score: 0.682\n",
            "Best parameters set:\n",
            "\tclassifier__alpha: 0.5\n",
            "\tfeatures__pipe__vect__max_df: 0.95\n",
            "\tfeatures__pipe__vect__min_df: 2\n",
            "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
            "Test score with best_estimator_: 0.758\n",
            "\n",
            "\n",
            "Classification Report Test Data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.81      0.89      0.85       893\n",
            "           0       0.59      0.46      0.52       326\n",
            "           1       0.71      0.68      0.69       245\n",
            "\n",
            "    accuracy                           0.76      1464\n",
            "   macro avg       0.70      0.67      0.69      1464\n",
            "weighted avg       0.75      0.76      0.75      1464\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v1X9upB_z9Gi"
      },
      "source": [
        "**Best parameters set:**\n",
        "\t\n",
        "  classifier__C: 0.5\n",
        "\t\n",
        "  classifier__penalty: 'l2'\n",
        "\t\n",
        "  features__pipe__vect__max_df: 0.95\n",
        "\t\n",
        "  features__pipe__vect__min_df: 1\n",
        "\t\n",
        "  features__pipe__vect__ngram_range: (1, 1)\n",
        "\n",
        "Test score with best_estimator_: 0.777"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4z1VbEFEz9Gj"
      },
      "source": [
        "## **Predict F1 score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XVodRtLDz9Gk",
        "colab": {}
      },
      "source": [
        "y_pred = best_MNB_cvec.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EuBP00p1z9Gq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f9208cd-9864-49e6-faca-169d105ff10b"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1464,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CUHGeM4Bz9G0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "564763c6-56f0-4224-b51e-976add985e18"
      },
      "source": [
        "mean_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "mean_f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6854784872950964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qdgjzcanz9G_"
      },
      "source": [
        "# **Multinomial NB with Tfidf Transformer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xpqgb0xYz9HB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "e429b079-9a14-40a5-9da7-bb481bf76ab8"
      },
      "source": [
        "# LogisticRegressionWithTfidf\n",
        "best_MNB_tfidf = grid_search_fn(MNB, parameters_MNB, X_train, X_test, parameters_vect=parameters_tfidf, vect=tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['features', 'classifier']\n",
            "parameters:\n",
            "{'classifier__alpha': (0.25, 0.5, 0.75),\n",
            " 'features__pipe__vect__max_df': (0.95, 1.0),\n",
            " 'features__pipe__vect__min_df': (1, 2),\n",
            " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   21.9s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done in 22.126s\n",
            "\n",
            "Best CV score: 0.613\n",
            "Best parameters set:\n",
            "\tclassifier__alpha: 0.25\n",
            "\tfeatures__pipe__vect__max_df: 0.95\n",
            "\tfeatures__pipe__vect__min_df: 2\n",
            "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
            "Test score with best_estimator_: 0.725\n",
            "\n",
            "\n",
            "Classification Report Test Data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.74      0.95      0.83       893\n",
            "           0       0.64      0.32      0.42       326\n",
            "           1       0.70      0.47      0.56       245\n",
            "\n",
            "    accuracy                           0.73      1464\n",
            "   macro avg       0.69      0.58      0.60      1464\n",
            "weighted avg       0.71      0.73      0.69      1464\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kTM1Dc-Vz9HI"
      },
      "source": [
        "## **Predict F1 score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vxIE0ywNz9HJ",
        "colab": {}
      },
      "source": [
        "y_pred = best_MNB_tfidf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5TP85hbbz9HR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44a567bb-1fcf-4477-ebf6-e3a9c0253e21"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1464,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9wnPH-0rz9HZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c352eb80-390c-42bc-ed8a-576ae50dbc15"
      },
      "source": [
        "mean_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "mean_f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.604368431014286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v497pBHd-gdP"
      },
      "source": [
        "# **XG Boost with Count Vectorizer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v9axx_nu-rz_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "b3b7c3c6-c54f-4912-e48e-3073ec5477ca"
      },
      "source": [
        "# LogisticRegressionWithTfidf\n",
        "best_XGB_cvec = grid_search_fn(XGB, parameters_XGB, X_train, X_test, parameters_vect=parameters_cvec, vect=cvec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['features', 'classifier']\n",
            "parameters:\n",
            "{'classifier__max_depth': [3, 4, 5],\n",
            " 'features__pipe__vect__max_df': (0.95, 1.0),\n",
            " 'features__pipe__vect__min_df': (1, 2),\n",
            " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 11.3min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done in 702.836s\n",
            "\n",
            "Best CV score: 0.671\n",
            "Best parameters set:\n",
            "\tclassifier__max_depth: 5\n",
            "\tfeatures__pipe__vect__max_df: 0.95\n",
            "\tfeatures__pipe__vect__min_df: 1\n",
            "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
            "Test score with best_estimator_: 0.749\n",
            "\n",
            "\n",
            "Classification Report Test Data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.78      0.92      0.84       893\n",
            "           0       0.64      0.44      0.52       326\n",
            "           1       0.70      0.54      0.61       245\n",
            "\n",
            "    accuracy                           0.75      1464\n",
            "   macro avg       0.71      0.63      0.66      1464\n",
            "weighted avg       0.74      0.75      0.73      1464\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i8937JzB-r0S"
      },
      "source": [
        "## **Predict F1 score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EuK__6Jq-r0V",
        "colab": {}
      },
      "source": [
        "y_pred = best_XGB_cvec.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cc5rD2gp-r0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e570290-82b7-4cc5-af92-9e9bcc225836"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1464,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y8y7Nk3U-r0t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7d1adfa-e134-4add-a83c-13af8d61e012"
      },
      "source": [
        "mean_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "mean_f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6590628189700366"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A8ts2VjV-9k4"
      },
      "source": [
        "# **XG Boost with Tfidf Transformer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3NlEH-lB-gdT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "a8c5510e-7c2b-47fc-a2c5-980eb8ef15d5"
      },
      "source": [
        "# LogisticRegressionWithTfidf\n",
        "best_XGB_tfidf = grid_search_fn(XGB, parameters_XGB, X_train, X_test, parameters_vect=parameters_tfidf, vect=tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['features', 'classifier']\n",
            "parameters:\n",
            "{'classifier__max_depth': [3, 4, 5],\n",
            " 'features__pipe__vect__max_df': (0.95, 1.0),\n",
            " 'features__pipe__vect__min_df': (1, 2),\n",
            " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 14.0min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done in 849.434s\n",
            "\n",
            "Best CV score: 0.670\n",
            "Best parameters set:\n",
            "\tclassifier__max_depth: 5\n",
            "\tfeatures__pipe__vect__max_df: 0.95\n",
            "\tfeatures__pipe__vect__min_df: 2\n",
            "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
            "Test score with best_estimator_: 0.742\n",
            "\n",
            "\n",
            "Classification Report Test Data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.78      0.90      0.84       893\n",
            "           0       0.61      0.43      0.50       326\n",
            "           1       0.71      0.56      0.63       245\n",
            "\n",
            "    accuracy                           0.74      1464\n",
            "   macro avg       0.70      0.63      0.66      1464\n",
            "weighted avg       0.73      0.74      0.73      1464\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "72k3ygn_-gdi"
      },
      "source": [
        "## **Predict F1 score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4e1dk_yV-gdk",
        "colab": {}
      },
      "source": [
        "y_pred = best_XGB_tfidf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6B7psoBE-gep",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4467acfb-45a8-45ba-c178-442982e3b7f3"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1464,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f-Tlvezh-gez",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6d0a601-fe21-483c-dbbb-2b6d921b4814"
      },
      "source": [
        "mean_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "mean_f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6562600130194055"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTaSunkwQppl",
        "colab_type": "text"
      },
      "source": [
        "# **Prediction on Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9It1ymRWMF45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "60b34bfa-f3ee-4b10-a04e-22fe5a9640d0"
      },
      "source": [
        "test_tweets.text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       @AmericanAir In car gng to DFW. Pulled over 1h...\n",
              "1       @AmericanAir after all, the plane didnÂÃÂªt ...\n",
              "2       @SouthwestAir can't believe how many paying cu...\n",
              "3       @USAirways I can legitimately say that I would...\n",
              "4       @AmericanAir still no response from AA. great ...\n",
              "                              ...                        \n",
              "7315    @JetBlue Traveling with two kids tomorrow (age...\n",
              "7316    @JetBlue Tx for the info. Just don't understan...\n",
              "7317    @AmericanAir I understand. But why is this the...\n",
              "7318                                 @USAirways really!??\n",
              "7319    @united no I did not make connection.  Your st...\n",
              "Name: text, Length: 7320, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fiEIPdh0PIdd",
        "colab": {}
      },
      "source": [
        "X = test_tweets.drop(['id'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uRojwJIUPIdu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "20b3ca69-4057-469f-d3c5-058e165f9dd1"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@AmericanAir after all, the plane didnÂÃÂªt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@USAirways I can legitimately say that I would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@AmericanAir still no response from AA. great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7315</th>\n",
              "      <td>@JetBlue Traveling with two kids tomorrow (age...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7316</th>\n",
              "      <td>@JetBlue Tx for the info. Just don't understan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7317</th>\n",
              "      <td>@AmericanAir I understand. But why is this the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7318</th>\n",
              "      <td>@USAirways really!??</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7319</th>\n",
              "      <td>@united no I did not make connection.  Your st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7320 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text\n",
              "0     @AmericanAir In car gng to DFW. Pulled over 1h...\n",
              "1     @AmericanAir after all, the plane didnÂÃÂªt ...\n",
              "2     @SouthwestAir can't believe how many paying cu...\n",
              "3     @USAirways I can legitimately say that I would...\n",
              "4     @AmericanAir still no response from AA. great ...\n",
              "...                                                 ...\n",
              "7315  @JetBlue Traveling with two kids tomorrow (age...\n",
              "7316  @JetBlue Tx for the info. Just don't understan...\n",
              "7317  @AmericanAir I understand. But why is this the...\n",
              "7318                               @USAirways really!??\n",
              "7319  @united no I did not make connection.  Your st...\n",
              "\n",
              "[7320 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xMAErFnbPId4",
        "colab": {}
      },
      "source": [
        "# Based on https://www.freecodecamp.org/news/sentiment-analysis-with-text-mining/\n",
        "\n",
        "def feature_counts(X):\n",
        "        #all the alphanumeric character\n",
        "        count_words = X.apply(lambda x: count_regex(r'\\w+', x)) \n",
        "        count_mentions = X.apply(lambda x: count_regex(r'@\\w+', x))\n",
        "        count_hashtags = X.apply(lambda x: count_regex(r'#\\w+', x))\n",
        "        count_capital_words = X.apply(lambda x: count_regex(r'\\b[A-Z]{2,}\\b', x))\n",
        "        count_excl_quest_marks = X.apply(lambda x: count_regex(r'!|\\?+', x))\n",
        "        count_urls = X.apply(lambda x: count_regex(r'https?://[^\\s]+[\\s]?', x))\n",
        "        # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n",
        "        # Moreover, it will result in having more words in the tweet\n",
        "        count_emojis = X.apply(lambda x: emoji.demojize(x)).apply(lambda x: count_regex(r':[a-z_&]+:', x))\n",
        "        \n",
        "        df = pd.DataFrame({'count_words': count_words\n",
        "                           , 'count_mentions': count_mentions\n",
        "                           , 'count_hashtags': count_hashtags\n",
        "                           , 'count_capital_words': count_capital_words\n",
        "                           , 'count_excl_quest_marks': count_excl_quest_marks\n",
        "                           , 'count_urls': count_urls\n",
        "                           , 'count_emojis': count_emojis\n",
        "                          })\n",
        "        \n",
        "        return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lGlCSTeOPId9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "c9bf7e29-a80c-4b09-97fe-114fdccdd44f"
      },
      "source": [
        "X_feat_counts = feature_counts(X.text)\n",
        "X_feat_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count_words</th>\n",
              "      <th>count_mentions</th>\n",
              "      <th>count_hashtags</th>\n",
              "      <th>count_capital_words</th>\n",
              "      <th>count_excl_quest_marks</th>\n",
              "      <th>count_urls</th>\n",
              "      <th>count_emojis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7315</th>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7316</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7317</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7318</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7319</th>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7320 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      count_words  count_mentions  ...  count_urls  count_emojis\n",
              "0              28               1  ...           0             0\n",
              "1              19               1  ...           0             0\n",
              "2              25               1  ...           0             0\n",
              "3              18               1  ...           0             0\n",
              "4               9               1  ...           0             0\n",
              "...           ...             ...  ...         ...           ...\n",
              "7315           21               1  ...           0             0\n",
              "7316           24               1  ...           0             0\n",
              "7317           28               1  ...           0             0\n",
              "7318            2               1  ...           0             0\n",
              "7319           23               1  ...           0             0\n",
              "\n",
              "[7320 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4baS-ST4PIeC"
      },
      "source": [
        "## **Text Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uwbMoOGTPIeD",
        "colab": {}
      },
      "source": [
        "# Shorter version of http://sentiment.christopherpotts.net/code-data/happyfuntokenizing.py\n",
        "# Shorter version adapted from https://github.com/dbamman/anlp19/blob/master/1.words/ExploreTokenization.ipynb\n",
        "\n",
        "# The order here is important (match from first to last)\n",
        "import re\n",
        "\n",
        "# Keep usernames together (any token starting with @, followed by A-Z, a-z, 0-9)\n",
        "regexes=(r\"(?:@[\\w_]+)\",\n",
        "\n",
        "# Keep hashtags together (any token starting with #, followed by A-Z, a-z, 0-9, _, or -)\n",
        "r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\",\n",
        "\n",
        "# Keep words with apostrophes, hyphens and underscores together\n",
        "#r\"(?:[a-z][a-z’'\\-_]+[a-z])\",\n",
        "\n",
        "# Keep all other sequences of A-Z, a-z, 0-9, _ together\n",
        "r\"(?:[\\w_]+)\",\n",
        "\n",
        "# Everything else that's not whitespace\n",
        "r\"(?:\\S)\"\n",
        ")\n",
        "\n",
        "big_regex=\"|\".join(regexes)\n",
        "\n",
        "my_extensible_tokenizer = re.compile(big_regex, re.VERBOSE | re.I | re.UNICODE)\n",
        "\n",
        "def my_extensible_tokenize(text):\n",
        "    return my_extensible_tokenizer.findall(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CQ1L7GF6PIeG",
        "colab": {}
      },
      "source": [
        "tokens = []\n",
        "tokens = [' '.join(my_extensible_tokenize(X.loc[i, \"text\"])) for i in range(len(X))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H8w2YxhYPIeI",
        "colab": {}
      },
      "source": [
        "X[\"token_text\"]=tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H_pofuiFPIeM",
        "colab": {}
      },
      "source": [
        "# Based on https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65\n",
        "# Based on https://www.freecodecamp.org/news/sentiment-analysis-with-text-mining/\n",
        "class CleanText(BaseEstimator, TransformerMixin):\n",
        "    def remove_mentions(self, input_text):\n",
        "        return re.sub(r'@\\w+', '', input_text)\n",
        "    \n",
        "    def remove_urls(self, input_text):\n",
        "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
        "    \n",
        "    def emoji_oneword(self, input_text):\n",
        "        # By compressing the underscore, the emoji is kept as one word\n",
        "        return input_text.replace('_','')\n",
        "    \n",
        "    def remove_punctuation(self, input_text):\n",
        "        # Make translation table\n",
        "        punct = string.punctuation\n",
        "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
        "        return input_text.translate(trantab)\n",
        "\n",
        "    def remove_digits(self, input_text):\n",
        "        return re.sub('\\d+', '', input_text)\n",
        "    \n",
        "    def to_lower(self, input_text):\n",
        "        return input_text.lower()\n",
        "    \n",
        "    def stemming(self, input_text):\n",
        "        porter = PorterStemmer()\n",
        "        words = input_text.split() \n",
        "        stemmed_words = [porter.stem(word) for word in words]\n",
        "        return \" \".join(stemmed_words)\n",
        "\n",
        "    def remove_stopwords(self, input_text):\n",
        "        stopwords_list = stopwords.words('english')\n",
        "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
        "        whitelist = [\"n't\", \"not\", \"no\",'who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
        "        words = input_text.split() \n",
        "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
        "        return \" \".join(clean_words) \n",
        "    \n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, **transform_params):\n",
        "        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.stemming).apply(self.remove_stopwords)\n",
        "        return clean_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "61tmB8OVPIeR",
        "colab": {}
      },
      "source": [
        "ct = CleanText()\n",
        "clean_text = []\n",
        "clean_text = ct.fit_transform(X.token_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FXUlYKgUPIeT",
        "colab": {}
      },
      "source": [
        "clean_text = pd.DataFrame(clean_text)\n",
        "clean_text.columns = ['clean_text']\n",
        "X[\"clean_text\"] = clean_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KOfDNLOMPIeX",
        "colab": {}
      },
      "source": [
        "X2 = pd.concat([X, X_feat_counts], axis=1, sort=False,ignore_index=True)\n",
        "X2.columns = ['text','token_text','clean_text','count_words', 'count_mentions', 'count_hashtags',\n",
        "       'count_capital_words', 'count_excl_quest_marks', 'count_urls',\n",
        "       'count_emojis']\n",
        "X=X2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KNgjKM9LPIeZ",
        "colab": {}
      },
      "source": [
        "feat_counts = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
        "                      ,'count_mentions','count_urls','count_words']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6Q_BRLLSzbz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "cea48814-f090-4cf1-93ab-177afc23efb6"
      },
      "source": [
        "best_logit_cvec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier__C': 0.5,\n",
              " 'classifier__penalty': 'l2',\n",
              " 'features__pipe__vect__max_df': 0.95,\n",
              " 'features__pipe__vect__min_df': 1,\n",
              " 'features__pipe__vect__ngram_range': (1, 1)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmcYgqYiUWgU",
        "colab_type": "text"
      },
      "source": [
        "## **Predict Labels with Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MgppVNRULKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = best_logit_cvec.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeVk-zyvnj3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame({'id': test_tweets.id, 'Target': test_labels}).to_csv('submission.csv', index =False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcUGbWn5fG3C",
        "colab_type": "text"
      },
      "source": [
        "## **Work Flow**\n",
        "\n",
        "1.   Custom Tokenizer function used\n",
        "2.   Text Cleaning (Stemming, StopWord Removal)\n",
        "3.   GridSearch CV \n",
        "4.   Model and Predict F1 score for different combinations\n",
        "\n",
        "> Machine Learning models used:\n",
        "\n",
        ">>  o\tLogistic Regression\n",
        "\n",
        ">>  o\tNaïve Bayes\n",
        "\n",
        ">>  o\tXGBoost\n",
        "\n",
        "5.   Text Processing on Test data\n",
        "6.   Predict on Test Data using Logistic Regression and CountVectorizer \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD-1in4pfCB1",
        "colab_type": "text"
      },
      "source": [
        "# **References**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuHgXnz5njiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65\n",
        "# Based on http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\n",
        "# Based on https://www.freecodecamp.org/news/sentiment-analysis-with-text-mining/\n",
        "# Based on https://www.kaggle.com/metadist/work-like-a-pro-with-pipelines-and-feature-unions\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}